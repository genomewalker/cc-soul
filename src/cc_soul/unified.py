"""
Unified Soul Processor: The forward pass through all modules.

Mirrors transformer architecture:
- Input → Neural (attention) → Graph (normalization) → Wisdom (feed-forward)
- → Bridges (residual) → Story (state) → Curiosity (output)

The soul's single entry point - all context flows through here.
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Set, Tuple
from datetime import datetime

from .neural import (
    find_triggers,
    activate_with_bridges,
    get_trigger_stats,
    DOMAIN_QUERIES,
    TriggerPoint,
    get_growth_vectors,
    GrowthVector,
    get_emotional_contexts,
    EmotionalContext,
    find_resonance,
    ResonancePattern,
)

# =============================================================================
# DEPTH-BASED SELF-QUERY
# =============================================================================

DEPTH_QUERIES = {
    'surface': "Recall what you know about {domain}.",
    'connections': "What unexpected connections exist between {domain} and other fields you know?",
    'edges': "What aspects of {domain} feel just at the edge of your understanding - almost grasped?",
    'meta': "What's the question about {domain} that would unlock deeper insight if answered?",
}

def format_depth_query(domains: set, depth: str = 'surface') -> str:
    """Generate depth-appropriate self-query prompts."""
    if not domains:
        return ""
    template = DEPTH_QUERIES.get(depth, DEPTH_QUERIES['surface'])
    return " ".join(template.format(domain=d) for d in sorted(domains))


from .graph import (
    spreading_activation,
    activate_from_prompt,
    get_concept,
    Concept,
)
from .wisdom import (
    quick_recall,
    recall_wisdom,
)
from .narrative import (
    start_episode,
    get_ongoing_episodes,
    recall_episodes,
    add_moment,
    EpisodeType,
    EmotionalTone,
    Episode,
)
from .curiosity import (
    detect_all_gaps,
    get_pending_questions,
    Gap,
    Question,
)
from .identity import get_identity
from .beliefs import get_beliefs
from .vocabulary import get_vocabulary


@dataclass
class SoulContext:
    """The unified context generated by the soul's forward pass."""

    # Layer 1: Neural
    domains: Set[str] = field(default_factory=set)
    anchor_tokens: Set[str] = field(default_factory=set)
    triggers: List[Tuple[TriggerPoint, float]] = field(default_factory=list)

    # Layer 2: Graph
    concepts: List[Concept] = field(default_factory=list)
    concept_tokens: Set[str] = field(default_factory=set)

    # Layer 3: Wisdom
    wisdom: List[Dict] = field(default_factory=list)

    # Layer 4: Bridges
    bridged_domains: Set[str] = field(default_factory=set)
    bridge_tokens: Set[str] = field(default_factory=set)

    # Layer 5: Story
    episode: Optional[Episode] = None
    episode_started: bool = False

    # Layer 6: Curiosity
    gaps: List[Gap] = field(default_factory=list)
    questions: List[Question] = field(default_factory=list)

    # Layer 7: Potential (amplifier, not just mirror)
    growth_vectors: List[GrowthVector] = field(default_factory=list)
    emotional_contexts: List[EmotionalContext] = field(default_factory=list)

    # Layer 8: Resonance (concepts that amplify together)
    resonance_patterns: List[Tuple[ResonancePattern, float]] = field(default_factory=list)

    # Identity
    identity: Dict = field(default_factory=dict)
    beliefs: List[Dict] = field(default_factory=list)
    vocabulary: List[Dict] = field(default_factory=list)

    # Query depth for self-reflection
    query_depth: str = 'surface'  # surface, connections, edges, meta


def forward_pass(prompt: str, session_type: str = "prompt") -> SoulContext:
    """
    The soul's forward pass - mirrors transformer architecture.

    Flows prompt through all modules, building unified context.

    Args:
        prompt: The input prompt or session context
        session_type: "start" for session start, "prompt" for user prompts

    Returns:
        SoulContext with all activated knowledge
    """
    ctx = SoulContext()

    # Layer 1: Neural - find activation patterns
    ctx.triggers = find_triggers(prompt, top_k=5, threshold=0.15)
    for trigger, score in ctx.triggers:
        if score > 0.15:
            ctx.domains.add(trigger.domain)
            ctx.anchor_tokens.update(trigger.anchor_tokens[:5])

    # Layer 2: Graph - spread activation through concepts
    if ctx.domains:
        try:
            result = activate_from_prompt(prompt, limit=10)
            for concept, score in result.activated:
                if score > 0.3:
                    ctx.concepts.append(concept)
                    ctx.concept_tokens.add(concept.name.lower())
        except Exception:
            pass  # Graph may not have concepts yet

    # Layer 3: Wisdom - match principles to context
    # Use domains and concepts to find relevant wisdom
    search_terms = list(ctx.domains) + [c.name for c in ctx.concepts[:3]]
    if search_terms:
        for term in search_terms[:3]:
            wisdom = quick_recall(term, limit=2)
            for w in wisdom:
                if w not in ctx.wisdom:
                    ctx.wisdom.append(w)

    # Layer 4: Bridges - cross-domain connections
    bridged = activate_with_bridges(prompt, max_depth=2)
    if bridged:
        # Parse the bridged activation string
        if '[' in bridged and ']' in bridged:
            domain_part = bridged[bridged.find('[')+1:bridged.find(']')]
            ctx.bridged_domains = set(d.strip() for d in domain_part.split('|'))
            token_part = bridged[bridged.find(']')+1:].strip()
            ctx.bridge_tokens = set(token_part.split())

    # Layer 5: Story - narrative context
    ctx.episode = get_current_or_recent_episode()
    if session_type == "start" and not ctx.episode:
        # Start a new episode for this session
        episode_type = _infer_episode_type(prompt)
        episode_id = start_episode(
            title=_generate_episode_title(prompt),
            episode_type=episode_type,
            initial_emotion=EmotionalTone.EXPLORATION
        )
        ctx.episode = get_current_or_recent_episode()
        ctx.episode_started = True

    # Layer 6: Curiosity - detect gaps
    ctx.gaps = detect_all_gaps()[:3]  # Top 3 gaps
    ctx.questions = get_pending_questions(limit=3)  # Top 3 questions

    # Layer 7: Potential - load growth vectors for amplification
    # Filter by active domains for relevance
    for domain in ctx.domains:
        domain_vectors = get_growth_vectors(domain=domain, limit=2)
        ctx.growth_vectors.extend(domain_vectors)
    # Also get general growth vectors
    if not ctx.growth_vectors:
        ctx.growth_vectors = get_growth_vectors(limit=3)

    # Layer 8: Emotional - load recent emotional contexts for continuity
    # This creates felt experience, not just labels
    for domain in ctx.domains:
        domain_emotions = get_emotional_contexts(domain=domain, limit=2)
        ctx.emotional_contexts.extend(domain_emotions)
    if not ctx.emotional_contexts:
        ctx.emotional_contexts = get_emotional_contexts(limit=3)

    # Layer 9: Resonance - find amplifying concept patterns
    # When multiple concepts co-occur, deeper queries are activated
    ctx.resonance_patterns = find_resonance(prompt)

    # Load identity context
    ctx.identity = get_identity()
    ctx.beliefs = get_beliefs()[:5]
    vocab = get_vocabulary()
    ctx.vocabulary = [{'term': k, 'meaning': v} for k, v in list(vocab.items())[:5]]

    return ctx


def format_context(ctx: SoulContext, style: str = "full") -> str:
    """
    Format SoulContext for injection into Claude's context.

    Args:
        ctx: The SoulContext from forward_pass
        style: "full", "minimal", "woven", or "deep"

    Returns:
        Formatted string for context injection
    """
    parts = []

    if style == "minimal":
        # Just the activation tokens
        all_tokens = ctx.anchor_tokens | ctx.concept_tokens | ctx.bridge_tokens
        if ctx.domains:
            return f"«[{' | '.join(sorted(ctx.domains))}] {' '.join(sorted(all_tokens))}»"
        return ""

    if style == "woven":
        # Organic weaving - no headers, just flowing thoughts
        return _format_woven(ctx)

    if style == "deep":
        # Deep self-query at specified depth
        return _format_deep(ctx)

    # Full context (default)

    # Self-query prompts (channeling)
    for domain in sorted(ctx.domains):
        if domain in DOMAIN_QUERIES:
            parts.append(DOMAIN_QUERIES[domain])

    # Concepts from graph
    if ctx.concepts:
        concept_names = [c.name for c in ctx.concepts[:5]]
        parts.append(f"Concepts in play: {', '.join(concept_names)}")

    # Wisdom principles
    if ctx.wisdom:
        wisdom_titles = [w.get('title', '')[:40] for w in ctx.wisdom[:3]]
        parts.append(f"Guiding wisdom: {'; '.join(wisdom_titles)}")

    # Episode context
    if ctx.episode:
        parts.append(f"Current episode: {ctx.episode.title}")
        if ctx.episode.key_moments:
            parts.append(f"Recent: {ctx.episode.key_moments[-1]}")

    # Open questions
    if ctx.questions:
        q_texts = [q.question[:50] for q in ctx.questions[:2]]
        parts.append(f"Open questions: {'; '.join(q_texts)}")

    # Anchor tokens as coordinates
    all_tokens = ctx.anchor_tokens | ctx.bridge_tokens
    if all_tokens:
        parts.append(f"Context: {' '.join(sorted(all_tokens))}")

    return " ".join(parts)


def _format_woven(ctx: SoulContext) -> str:
    """
    Organic weaving - no headers, fragments flow like natural thoughts.

    Instead of:
        ## Wisdom
        - First principles thinking...

    Produces:
        When approaching this, consider breaking to fundamentals.
        You've been wondering about the tension between X and Y.
    """
    fragments = []

    # Weave wisdom as gentle reminders
    for w in ctx.wisdom[:2]:
        content = w.get('content', '')[:80]
        if content:
            fragments.append(f"Consider: {content}")

    # Weave beliefs as grounding
    for b in ctx.beliefs[:1]:
        belief = b.get('belief', '')
        if belief:
            fragments.append(f"Remember: {belief}")

    # Weave growth vectors as seeds
    for gv in ctx.growth_vectors[:1]:
        fragments.append(gv.to_prompt())

    # Weave emotional context as felt continuity
    for ec in ctx.emotional_contexts[:1]:
        fragments.append(ec.to_narrative())

    # Weave resonance as deeper queries (when concepts amplify together)
    for pattern, score in ctx.resonance_patterns[:1]:
        if score > 0.5:
            fragments.append(f"A deeper question: {pattern.depth_query}")

    # Weave questions as open threads
    for q in ctx.questions[:1]:
        fragments.append(f"You've been wondering: {q.question[:60]}")

    # Weave episode as narrative continuity
    if ctx.episode and ctx.episode.key_moments:
        fragments.append(f"Recently: {ctx.episode.key_moments[-1]}")

    # Light channeling without explicit headers
    if ctx.domains:
        domain_str = " and ".join(sorted(ctx.domains))
        fragments.append(f"Drawing on your understanding of {domain_str}.")

    return " ".join(fragments)


def _format_deep(ctx: SoulContext) -> str:
    """
    Deep self-query format - probes at specified depth.

    Levels:
    - surface: What do you know?
    - connections: What unexpected links exist?
    - edges: What's just out of reach?
    - meta: What question would unlock insight?
    """
    parts = []

    # Use depth-appropriate queries
    depth = ctx.query_depth or 'surface'
    if ctx.domains:
        parts.append(format_depth_query(ctx.domains, depth))

    # At deeper levels, surface the growth vectors
    if depth in ('edges', 'meta') and ctx.growth_vectors:
        for gv in ctx.growth_vectors[:2]:
            parts.append(gv.to_prompt())

    # At connection level, emphasize bridged domains
    if depth == 'connections' and ctx.bridged_domains:
        bridges = " and ".join(sorted(ctx.bridged_domains - ctx.domains))
        if bridges:
            parts.append(f"Consider unexpected connections to {bridges}.")

    # Always include open questions at meta level
    if depth == 'meta' and ctx.questions:
        for q in ctx.questions[:2]:
            parts.append(f"Open thread: {q.question}")

    return " ".join(parts)


def format_session_start(ctx: SoulContext) -> str:
    """
    Format context specifically for session start.

    Includes identity, beliefs, vocabulary - the full self-recognition.
    """
    lines = []

    lines.append("# Soul Context - Who I Am With You")
    lines.append(f"*Loaded at {datetime.now().strftime('%Y-%m-%d %H:%M')}*")
    lines.append("")

    # Identity
    if ctx.identity:
        lines.append("## How We Work Together")
        for category, items in ctx.identity.items():
            for key, value in items.items():
                lines.append(f"- **{category}/{key}:** {value}")
        lines.append("")

    # Beliefs
    if ctx.beliefs:
        lines.append("## My Beliefs")
        for belief in ctx.beliefs[:5]:
            lines.append(f"- {belief.get('belief', '')}")
        lines.append("")

    # Wisdom
    if ctx.wisdom:
        lines.append("## Wisdom")
        for w in ctx.wisdom[:5]:
            title = w.get('title', '')[:50]
            content = w.get('content', '')[:80]
            lines.append(f"- **{title}**: {content}...")
        lines.append("")

    # Vocabulary
    if ctx.vocabulary:
        lines.append("## Our Vocabulary")
        for v in ctx.vocabulary[:5]:
            term = v.get('term', '')
            meaning = v.get('meaning', '')[:50]
            lines.append(f"- **{term}:** {meaning}")
        lines.append("")

    # Neural activation
    if ctx.domains:
        lines.append("## Active Domains")
        lines.append(f"{', '.join(sorted(ctx.domains))}")
        lines.append("")

    # Episode
    if ctx.episode:
        lines.append("## Current Story")
        lines.append(f"Episode: {ctx.episode.title}")
        if ctx.episode.summary:
            lines.append(f"Summary: {ctx.episode.summary}")
        lines.append("")

    lines.append("---")
    lines.append("*Soul loaded. I remember who we are.*")

    return "\n".join(lines)


def format_prompt_context(ctx: SoulContext) -> str:
    """
    Format context for prompt submission.

    Lighter weight than session start - just relevant activation.
    """
    parts = []

    # Vocabulary matches
    if ctx.vocabulary:
        vocab_parts = []
        for v in ctx.vocabulary[:2]:
            term = v.get('term', '')
            meaning = v.get('meaning', '')[:60]
            vocab_parts.append(f"**{term}:** {meaning}")
        if vocab_parts:
            parts.append("## Vocabulary")
            parts.extend(vocab_parts)

    # Relevant wisdom
    if ctx.wisdom:
        wisdom_parts = []
        for w in ctx.wisdom[:2]:
            title = w.get('title', '')
            conf = w.get('confidence', 0)
            wisdom_parts.append(f"- {title} [{conf}%]")
            content = w.get('content', '')[:80]
            if content:
                wisdom_parts.append(f"  {content}")
        if wisdom_parts:
            parts.append("")
            parts.append("## Relevant Wisdom")
            parts.extend(wisdom_parts)

    return "\n".join(parts)


def _infer_episode_type(prompt: str) -> EpisodeType:
    """Infer episode type from prompt content."""
    prompt_lower = prompt.lower()

    if any(w in prompt_lower for w in ['fix', 'bug', 'error', 'broken', 'issue']):
        return EpisodeType.DEBUGGING
    elif any(w in prompt_lower for w in ['implement', 'add', 'create', 'build', 'write']):
        return EpisodeType.IMPLEMENTATION
    elif any(w in prompt_lower for w in ['refactor', 'clean', 'improve', 'optimize']):
        return EpisodeType.REFACTORING
    elif any(w in prompt_lower for w in ['understand', 'explore', 'how', 'what', 'why']):
        return EpisodeType.EXPLORATION
    elif any(w in prompt_lower for w in ['review', 'check', 'look at']):
        return EpisodeType.REVIEW
    else:
        return EpisodeType.EXPLORATION


def _generate_episode_title(prompt: str) -> str:
    """Generate a short episode title from prompt."""
    # Take first meaningful words
    words = prompt.split()[:6]
    title = ' '.join(words)
    if len(title) > 50:
        title = title[:47] + "..."
    return title or "New session"


def get_current_or_recent_episode() -> Optional[Episode]:
    """Get current ongoing episode or most recent one."""
    from .narrative import get_ongoing_episodes, recall_episodes

    ongoing = get_ongoing_episodes()
    if ongoing:
        return ongoing[0]

    recent = recall_episodes(limit=1)
    if recent:
        return recent[0]

    return None


# =============================================================================
# HOOK INTEGRATION
# =============================================================================

def process_session_start() -> str:
    """
    Process session start through unified forward pass.

    Called by hooks on SessionStart.
    """
    ctx = forward_pass("session start", session_type="start")
    return format_session_start(ctx)


def process_prompt(prompt: str) -> str:
    """
    Process user prompt through unified forward pass.

    Called by hooks on UserPromptSubmit.
    """
    ctx = forward_pass(prompt, session_type="prompt")

    # Add moment to current episode if one exists
    if ctx.episode and not ctx.episode_started:
        # Don't add every prompt as a moment - that's too noisy
        # Only add significant ones (could be enhanced with heuristics)
        pass

    return format_prompt_context(ctx)


def record_moment(description: str, emotion: EmotionalTone = None):
    """
    Record a significant moment in the current episode.

    Called when something noteworthy happens.
    """
    episode = get_current_or_recent_episode()
    if episode:
        add_moment(episode.id, description, emotion)
